{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "78825152",
   "metadata": {},
   "source": [
    "# Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff6251ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27d388ef",
   "metadata": {},
   "source": [
    "Reading in the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a51d2370",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.ipynb_checkpoints',\n",
       " 'DS Technical Assessment - John Weldon.ipynb',\n",
       " 'Exploration.ipynb',\n",
       " 'L2 Data Scientist Assessment - Data.csv',\n",
       " 'L2 Data Scientist Assessment - Data.xlsx',\n",
       " 'L2 Data Scientist Assessment - Instructions.docx']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d82200d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('L2 Data Scientist Assessment - Data.csv', dtype = str, encoding = 'cp1252')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19d564f6",
   "metadata": {},
   "source": [
    "Quick look at what columns are in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "866b3e99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['class', 'precision', 'sensitivity', 'f1', 'specificity',\n",
       "       'accuracy', 'mcc', 'dor', 'TP', 'FP', 'FN', 'TN', 'anno_set',\n",
       "       'classifier', 'metric_type', 'organ', 'magnification', 'model',\n",
       "       'dropoutFraction', 'layerDepth', 'numberOfEpochs', 'trainPercent',\n",
       "       'validationPercent', 'patience', 'checkPointAccuracy',\n",
       "       'augmentColor', 'augmentGeometry', 'balanceClasses',\n",
       "       'elasticDeform', 'fixedDataSeed', 'augmentation', 'overlapPredict',\n",
       "       'pretrained', 'focalLoss', 'filterSize', 'kernelIncrease',\n",
       "       'normalization', 'magLayers', 'model_name', 'backbone_name',\n",
       "       'encoder_freeze', 'decoder_use_batchnorm', 'middleBlocks', 'loss',\n",
       "       'optimizer', 'learningRate', 'useFP16', 'useAllGPUs',\n",
       "       'time_evaluated', 'balance only', 'balance + elastic'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns.values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1ab986d",
   "metadata": {},
   "source": [
    "Check what classes there are"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "82d5a1df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Background', 'Tissue', 'Lesions'], dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['class'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fc5896f",
   "metadata": {},
   "source": [
    "Convert certain columns to numeric fields for calculations later on and use the sum of TP/FP/TN/FN to see how many total Pixels there are in the image dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "557cab9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([71565312])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['TP'] = data['TP'].astype(int)\n",
    "data['FP'] = data['FP'].astype(int)\n",
    "data['TN'] = data['TN'].astype(int)\n",
    "data['FN'] = data['FN'].astype(int)\n",
    "\n",
    "data['f1'] = data['f1'].astype(float)\n",
    "data['accuracy'] = data['accuracy'].astype(float)\n",
    "\n",
    "data['Check'] = data['TP'] + data['FP'] + data['TN'] + data['FN']\n",
    "data['Check'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c57a4baa",
   "metadata": {},
   "source": [
    "Create separate dataframes for each class and check the size of these"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "664058c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(263, 263, 263)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "background = data[data['class'] == 'Background']\n",
    "tissue = data[data['class'] == 'Tissue']\n",
    "lesions = data[data['class'] == 'Lesions']\n",
    "\n",
    "len(background), len(tissue), len(lesions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e358b300",
   "metadata": {},
   "source": [
    "Creating some useful variables to describe the given dataset and also the image dataset that was classified "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8813dadb",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_tissue_pixels = tissue['TP'].iloc[0] + tissue['FN'].iloc[0]\n",
    "total_background_pixels = background['TP'].iloc[0] + background['FN'].iloc[0]\n",
    "total_lesions_pixels = lesions['TP'].iloc[0] + lesions['FN'].iloc[0]\n",
    "total_pixels = total_tissue_pixels + total_background_pixels + total_lesions_pixels\n",
    "total_classifiers = len(data['classifier'].unique())\n",
    "total_models = len(data['model'].unique())\n",
    "total_experiments = len(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "517dd3ba",
   "metadata": {},
   "source": [
    "Output some details about the given dataset and also derived details about the image dataset the experimentation was performed on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f2bea737",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Dataset Contains 71565312 total Pixels\n",
      "\n",
      "Image Dataset Contains 273 Images if each Image is 512x512 in size\n",
      "Image Dataset Contains 1092 Images if each Image is 256x256 in size\n",
      "\n",
      "79.76% of all Pixels are Tissue\n",
      "15.18% of all Pixels are Background\n",
      "5.06% of all Pixels are Lesions\n",
      "\n",
      "Experiment Dataset Contains 789 total Experiments\n",
      "Experiment Dataset Contains 263 unique Classifiers\n",
      "Experiment Dataset Contains 8 unique Models\n"
     ]
    }
   ],
   "source": [
    "print(f'''Image Dataset Contains {int(total_pixels)} total Pixels\\n\n",
    "Image Dataset Contains {int(total_pixels/(512*512))} Images if each Image is 512x512 in size\n",
    "Image Dataset Contains {int(total_pixels/(256*256))} Images if each Image is 256x256 in size\\n\n",
    "{total_tissue_pixels/total_pixels*100:.2f}% of all Pixels are Tissue\n",
    "{total_background_pixels/total_pixels*100:.2f}% of all Pixels are Background\n",
    "{total_lesions_pixels/total_pixels*100:.2f}% of all Pixels are Lesions\\n\n",
    "Experiment Dataset Contains {total_experiments} total Experiments\n",
    "Experiment Dataset Contains {total_classifiers} unique Classifiers\n",
    "Experiment Dataset Contains {total_models} unique Models''')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e95381f6",
   "metadata": {},
   "source": [
    "Quick check to see how difficult the three classes are to classify, looks like Lesions are the trickiest which makes sense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "49b0c947",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9125192610228134, 0.9624642129459462, 0.5763340164594591)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tissue_f1_mean = tissue['f1'].mean()\n",
    "background_f1_mean = background['f1'].mean()\n",
    "lesions_f1_mean = lesions['f1'].mean()\n",
    "\n",
    "background_f1_mean, tissue_f1_mean, lesions_f1_mean"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
